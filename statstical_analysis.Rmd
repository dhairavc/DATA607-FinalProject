---
title: "DATA607 Final Project"
author: "Salma Elshahawy, Mael Illien, Dhairav Chhatbar"
date: "11/18/2019"
output: 
  html_document:
    theme: united
    df_print: paged
    toc: true
    toc_float: 
      collapsed: true
      smooth_scroll: true
    number_sections: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# A Socio-Economic Investigation into Crime

Presented by:

+ Salma Elshahawy [salma71](https://github.com/salma71)
+ Dhairav Chhatbar [dhairavc](https://github.com/dhairavc)
+ Mael Illien [maelillien](https://github.com/maelillien) 

## Introduction

This project provided us with the opportunity of showcasing many of the skills we have learned throughout this course and of applying them to an investigation into datasets of our choosing. We narrowed our scope to a few datasets containing information on social economic information, namely unemployment and crime data in NYC. Specifically we wanted to explore the impact of unemployment on crime within New York City. The guiding question for our statistical analysis if the following hypothesis:

\[H0: Unemployment \ does \ not \ impact \ crime\ (R^2 = 0) \]
\[HA: Unemployment \ does \ impact \ crime\ (R^2 > 0) \]


We hoped that this investigation alongside exploratory data analysis would provide us with useful information that could be used to formulate policy proposals. We used the following process for each dataset:	

1. Data Import (API and .csv)	
2. Data Transformation (handling missing data, tidying)	
3. Data Exploration & Analysis (commentary, visualizations)	

We then merged the datasets to explore further and try to draw some final conslusions based on the resulting model.

## Work flow-chart

![workflowchart](./workflowchart.png)

## Sources of Datasets

- [NYPD Arrests Data Historic](https://data.cityofnewyork.us/Public-Safety/NYPD-Arrests-Data-Historic-/8h9b-rp9u)
- [Unemployment data from the Department of Labor](https://www.labor.ny.gov/stats/nyc/)


## Environment Setup

The packages are loaded from a separate R file.

```{r environment setup, message=FALSE, warning=FALSE}
source("environment_setup.R", echo = T, prompt.echo = "", spaced = F)
```

# NYPD Arrests
The NYPD Arrests database provides observations of confirmed (individuals NOT acquitted of all charges) crimes that are reported to the New York City Police Department (NYPD)  

## NYPD Arrests - Data Import via API

We will start with the NYPD Arrests Data (Historic) data from NYC Open Data found below and conduct some exploratory data analysis to find out how arrests are distributed in general. We will explore trends like for example investigating seasonality trends or trends in particular kinds of arrest or by boroughs.

There are 4.8M rows, there are 18 columns and each row is an arrest.


variable         | description
---------------- | -----------
`arrest_date`    | Exact date of arrest for the reported event.
`ofns_desc`      | Description of internal classification corresponding with KY code (more general category than PD description).
`arrest_boro`    | Borough of arrest. B(Bronx), S(Staten Island), K(Brooklyn), M(Manhattan), Q(Queens)
`age_group`      | Perpetrator’s age within a category.
`perp_sex`       | Perpetrator’s sex description.
`perp_race`      | Perpetrator’s race description.
`x_coord_cd`     | Midblock X-coordinate for New York State Plane Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104).
`y_coord_cd`     | Midblock Y-coordinate for New York State Plane Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104)
`latitude`       | Latitude coordinate for Global Coordinate System, WGS 1984, decimal degrees (EPSG 4326)
`longitude`      | Longitude coordinate for Global Coordinate System, WGS 1984, decimal degrees (EPSG 4326)

Load the data into R using the RSocrata API.

```{r arrests, warning=FALSE, message=FALSE}
source("arrests_dataset.R", echo = F, prompt.echo = "", spaced = F)
head(arrests_df, 10)
```

## NYPD Arrests - Data Transformation

Rename the borough letters to proper names.

```{r change boro names, message=FALSE, warning=FALSE}
arrests_df$arrest_boro <- revalue(arrests_df$arrest_boro, c("Q"="Queens", "K"="Brooklyn", "M"="Manhattan", "S"="Staten Island", "B" = "Bronx")) 
```

Remove missing values where no offense description is recorded.

```{r remove empty ofns, warning=FALSE, message=FALSE}
arrests_df <- arrests_df %>% filter(ofns_desc != "")
```

We generate a series of data frames aggregating the data in different manners for analysis and plotting. For example, we look at arrests by race, borough, offense.

```{r aggregation, message=FALSE, warning=FALSE}
murder_counts <- arrests_df %>%
  group_by(arrest_boro, year, perp_race) %>%
  dplyr::summarise(murder_counts = n()) %>%
  arrange(desc(year))
murder_counts
```

```{r arrests counts, message=FALSE, warning=FALSE}
# get the count of arrests per year, by borough
grouped_boro <- arrests_df %>% 
  group_by(year, arrest_boro) %>% 
  dplyr::summarize(count = n()) %>% 
  arrange(desc(count))
```

```{r ofnse counts, message=FALSE, warning=FALSE}
# get the count of offenses per year, by borough
grouped_offenses <- arrests_df %>% 
  group_by(year, arrest_boro, ofns_desc) %>% 
  dplyr::summarize(count = n()) %>%
  arrange(desc(count))
```

```{r top five ofnse, message=FALSE, warning=FALSE}
# get the top five offense per borough
t5 <- grouped_offenses %>% top_n(5)
```

```{r counts ofns overall, message=FALSE, warning=FALSE}
# get the counts of offenses overall
crime_counts <- arrests_df %>% 
  group_by(ofns_desc) %>% 
  dplyr::summarize(count = n()) %>% 
  arrange(desc(count))
```

```{r arrests count relative to dangerous drugs, message=FALSE, warning=FALSE}
# get the count of arrests related to dangerous drugs by year, by borough
drugs <- arrests_df %>% 
  filter(ofns_desc == 'DANGEROUS DRUGS') %>% 
  group_by(year, arrest_boro) %>% 
  dplyr::summarize(count = n())
```

## NYPD Arrest - Data Exploration & Analysis

### Evolution of Crime 2014-2018

Let's study the evolution of crime over the period of interest (2014-2018).

What the plot below reveals is that overall crime is decreasing for all boroughs of NYC. The data year over year is very similar, appearing to simply scale down over time. 

```{r crimes by boro time series, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(grouped_boro, aes(x = reorder(year, -count), y = count, fill = arrest_boro)) + 
  geom_bar(stat = 'identity', position = position_dodge()) +
  scale_y_continuous(labels=function(x) format(x, big.mark = ",", scientific = FALSE), breaks = seq(0,120000,10000)) +
  xlab("year") + ylab("total crime") + ggtitle("Crime by Borough Time Series") +
  scale_fill_brewer(palette="Blues") + theme_minimal()
```

What we can note as suprising is the fact that total crime between Manhattan and Brooklyn is at fairly similar levels. Total crime is aggregated without accounting for different types of crime so we will further our investigation by looking at top crimes overall, and then dissecting crime per borough.

Here is a plot of the top 10 most common crimes for the 2014-2018 period across all boroughs. We learn that dangerous drugs related offenses are the most prevailent followed by 3rd degree assaults.

```{r most common crimes, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(crime_counts %>% top_n(10), aes(x = reorder(ofns_desc, -count), y = count)) + 
  geom_bar(stat = 'identity', fill= 'lightblue') + 
  scale_y_continuous(labels=function(x) format(x, big.mark = ",", scientific = FALSE), breaks = seq(0,300000,50000)) +
  geom_text(aes(label = count), hjust = 1.25, color='white') +
  coord_flip() + 
  xlab("offense") + ylab("count")  + ggtitle("Most Common Crimes 2014-2018") +
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=8))
```

A peek at the bottom 10 crimes for the same period reveals somewhat unexpected crimes like disruption of a religious service. It is interesting to note that while dangerous drugs offenses are the most common crime, only 1 person was arrested for being under the influence of drugs.

```{r least commo crimes, message=FALSE, warning=FALSE, echo=FALSE}
ggplot(crime_counts %>% top_n(-10), aes(x = reorder(ofns_desc, -count), y = count)) + 
  geom_bar(stat = 'identity', fill= 'lightblue') + 
  scale_y_continuous(labels=function(x) format(x, big.mark = ",", scientific = FALSE), breaks = seq(0,75,5)) +
  geom_text(aes(label = count), hjust = 1.25, color='white') +
  coord_flip() + 
  xlab("offense") + ylab("count")  + ggtitle("Least Common Crimes 2014-2018") +
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=8))
```

Following from  the exploration above, we take a deeper look at the most common crimes by borough. On the plot below, we once again see that how drug related offenses are the most common crimes and that this is consistent across boroughs. We notice that while Brooklyn and Manhattan had the most crimes, the Bronx captures the most drug arrests.

```{r top 5 crimes by boro, message=FALSE, warning=FALSE, echo=FALSE}
ggplot(t5, aes(x = reorder(arrest_boro, -count), y = count, fill=ofns_desc)) + 
  geom_bar(stat = 'identity', position = position_dodge()) +
  scale_y_continuous(labels=function(x) format(x, big.mark = ",", scientific = FALSE), breaks = seq(0,80000,5000)) +
  xlab("borough") + ylab("crime rate") + ggtitle("Top 5 Crimes by Borough") +
  scale_fill_brewer(palette="Blues") + theme_minimal()
```

The plot below explores that relationship over time for each borough. We observe that similarly to crime in general, drug related arrests are going down.

```{r dangerous drug crime, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(drugs, aes(x = year, y = count, color = arrest_boro)) +
  geom_line() + 
  scale_y_continuous(labels=function(x) format(x, big.mark = ",", scientific = FALSE), breaks = seq(0,30000,2500)) +
  xlab("year") + ylab("count")  + ggtitle("Dangerous Drugs Crime by Bourough") +
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=8))
  
```

We continue investigating the demographics and take a look at the distribution of crime by gender. Male adults between the ages of 25-44 remain the most common perpetrators. 

```{r age group gender distribution, message=FALSE, warning=FALSE, echo=FALSE}
ggplot(arrests_df, aes(x = age_group, fill = perp_sex)) + 
  geom_histogram(stat = "count", position=position_dodge()) +
  scale_fill_brewer(palette="Blues") + 
  xlab("age group") + ylab("count")  + ggtitle("Perpetrator Age Group and Gender Distribution") +
  scale_y_continuous(labels=function(x) format(x, big.mark = ",", scientific = FALSE), breaks = seq(0,7000000,100000))
```

This interactive map will let you explore the distribution of crime geographically.  

```{r map for arrests,echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
arrests_map <- arrests_df %>% filter(year == 2018)
singleicon <- makeIcon(iconUrl = "https://image.flaticon.com/icons/svg/1331/1331396.svg",
                       iconWidth = 45,
                       iconHeight = 45,
                       iconAnchorX = 0,
                       iconAnchorY = 0)
leaflet(arrests_map, width = '100%') %>% addTiles() %>% 
                                  addMarkers(lng = ~longitude, lat = ~latitude, 
                                             clusterOptions = markerClusterOptions(), 
                                             popup = paste("<b>Offense: </b>", arrests_map$ofns_desc, "<br/>",
                                                           "<b>Age Group: </b>", arrests_map$age_group, "<br/>",
                                                           "<b>Sex: </b>", arrests_map$perp_sex, "<br/>",
                                                           "<b>Race: </b>", arrests_map$perp_race),
                                             icon = singleicon)
```

# Labor Bureau
The labor dataset provides observations on the active labor force and the population that remains unemployed per boro 


## Labor Bureau - Data Import via .csv

We wanted to invistigate if there is a correlation between crimes and unemployment rate. So we tried to investigate another dataset from the labor bureau. The dataset has five tables for the five boroghs for a  period of four years from 2014 - 2018. 

```{r dataset per boro, message=FALSE, warning=FALSE, paged.print=TRUE}
source("unemployed_dataset.R", echo = F, prompt.echo = "", spaced = F)
head(bronx)
head(queens)
head(brooklyn)
head(manhattan)
head(staten)
```

## Labor Bureau - Data Transformation

```{r clean unemployed, message=FALSE, warning=FALSE}
clean_table <- function (table) {
  table_content <- table %>%
    na.omit()
  colnames(table_content) = c("arrest_boro","year","month","labor_force","employed","unemployed","unemployment_rate")
  final_table <- table_content %>%
    select(arrest_boro, year, labor_force, employed, unemployed, unemployment_rate) 
  return(final_table)
}
bronx_income <- clean_table(bronx)
queens_income <- clean_table(queens)
brooklyn_income <- clean_table(brooklyn)
manhattan_income <- clean_table(manhattan)
staten_income <- clean_table(staten)
income_table <- Reduce(function(...) merge(..., all=T), list(bronx_income, queens_income, brooklyn_income, manhattan_income, staten_income))
income_table 
```

## Labor Bureau - Data Exploration & Analysis

The following boxplot shows the unemployment rate distribution per borough per year. We can see that there is a decreasing trend in the unemployment rate over the years. However, the Bronx county seems to have the highest unemployment rate over the years of a range of 5 - 6%.

```{r explore income by boro, message=FALSE, warning=FALSE, echo=FALSE}
theme_set(theme_bw())
ggplot(income_table, aes(x=arrest_boro, y=unemployment_rate)) + 
    geom_boxplot(main = "Different boxplot for uneployment rate in the 5 counties over years",
        ylab = "Unemployment rate %",	
        xlab = "",
        col = "blue",
        border = "blue") +
facet_wrap(~year, scale="free") + 
  theme(axis.text.x = element_text(angle=60, vjust = 0.6)) +
  ggtitle("Average unemployment rate over the years")
```


```{r summarize avg unemployed, message=FALSE, warning=FALSE}
by_income <- income_table %>%
  group_by(arrest_boro, year) %>%
  dplyr::summarise(avg_unemployment_rate = max(unemployment_rate)) %>%
  arrange(desc(year))
by_income
```

# Combined Datasets

After understanding our datasets individually, we merged them into a single data frame based on the variable that were shared between the two sources, namely `year` and `arrest_boro`. This allowed us to extend our analysis to the variables in the combined dataset and to study how they behave in relation to each other.

```{r merge crime and by income, message=FALSE, warning=FALSE}
merged <- Reduce(function(...) merge(..., all=T), list(murder_counts, by_income)) %>%
  na.omit() %>%
  arrange(desc(year))
merged
```

We tried to plot a diverging plot to investigate which borough is above or below average. So we normalized the average unemployment rate and the number of crimes. Both Brooklyn and Bronx seem to have the most significant above average for crimes committed and the unemployment rate. 

```{r normalize unemployed, message=FALSE, warning=FALSE, echo=FALSE}
# Data Prep
merged$boro <- rownames(merged)  # create new column for boro names
merged$unemployment_z <- round((merged$avg_unemployment_rate - mean(merged$avg_unemployment_rate))/sd(merged$avg_unemployment_rate), 2)  # compute normalized 
merged$unemployyment_type <- ifelse(merged$unemployment_z < 0, "below", "above")  # above / below avg flag
merged <- merged[order(merged$unemployment_z), ]  # sort
# merged$arrest_boro <- factor(merged$arrest_boro, levels = merged$arrest_boro)  # convert to factor to retain sorted order in plot.
merged$arrest_boro <- factor(merged$arrest_boro, levels = rev(unique(merged$arrest_boro)), ordered=TRUE)
# Diverging Barcharts
ggplot(merged, aes(x=`arrest_boro`, y=unemployment_z, label=unemployment_z)) + 
  geom_bar(stat='identity', aes(fill=unemployyment_type), width=.5)  +
  scale_fill_manual(name="Unemployment", 
                    labels = c("Above Average", "Below Average"), 
                    values = c("above"="#f8766d", "below"="#00ba38")) + 
  labs(subtitle="Normalised unemployment rate from 'merged'", 
       title= "Diverging Bars of unemployment rates in boro") + 
  coord_flip()
```

```{r normalize crime, message=FALSE, warning=FALSE, echo=FALSE}
# Data Prep
merged$boro <- rownames(merged)  # create new column for boro names
merged$crime_z <- round((merged$murder_counts - mean(merged$murder_counts))/sd(merged$murder_counts), 2)  # compute normalized 
merged$murder_type <- ifelse(merged$crime_z < 0, "below", "above")  # above / below avg flag
merged <- merged[order(merged$crime_z), ]  # sort
# merged$arrest_boro <- factor(merged$arrest_boro, levels = merged$arrest_boro)  # convert to factor to retain sorted order in plot.
merged$arrest_boro <- factor(merged$arrest_boro, levels = rev(unique(merged$arrest_boro)), ordered=TRUE)
# Diverging Barcharts
ggplot(merged, aes(x=`arrest_boro`, y=crime_z, label=crime_z)) + 
  geom_bar(stat='identity', aes(fill=murder_type), width=.5)  +
  scale_fill_manual(name="Crimes", 
                    labels = c("Above Average", "Below Average"), 
                    values = c("above"="#f8766d", "below"="#00ba38")) + 
  labs(subtitle="Normalised crimes'", 
       title= "Diverging Bars of number of crimes per county") + 
  coord_flip()
```


 We can see that the 25-44 age category is the largest age category density for committing crimes across all boroughs. As also demonstrated, Bronx seems to have the highest density of crimes for all age categories amongst other boroughs. 


```{r density plot for age, message=FALSE, warning=FALSE, echo=FALSE, fig.width=10}
theme_set(theme_classic())
# Plot
g <- ggplot(arrests_df, aes(arrest_boro))
g + geom_density(aes(fill=factor(age_group)), alpha=0.8) + 
    labs(title="Density plot", 
         subtitle="Number of crimes per boro per age group distribution",
         caption="Source: arrests_df",
         x="Borough",
         fill="# crimes committed per age group") 
```

The treemap was used to study which race is common for committing a crime. As illustrated, BLACK is the typical race. However, Brooklyn appears to have more crimes committed by BLACK than the Bronx. 

```{r treemap for arrests, message=FALSE, warning=FALSE, echo=FALSE}
map <- murder_counts %>% filter(year == 2018)
treemap(map, #Your data frame object
        index=c("perp_race","arrest_boro"),  #A list of your categorical variables
        vSize = "murder_counts",  #This is your quantitative variable
        type="categorical", #Type sets the organization and color scheme of your treemap
        vColor = "arrest_boro", #Type sets the organization and color scheme of your treemap
        palette = "Set1",  #Select your color palette from the RColorBrewer presets or make your own.
        title="Crime distribution committed by different races - year 2018", #Customize your title
        fontsize.title = 14 #Change the font size of the title
        ) 
```

# Statistical Analysis & Modeling

To anser the initial hypothesized question, the combined dataset is utilized in a linear regression modeling exercise to understand the relationship between the variables. In this process we were able to identify which variables are the greatest predictors of the number of crimes commited.

```{r fetch complaindata 14-18, message=FALSE, warning=FALSE}
source("complain_dataset.R", echo = F, prompt.echo = "", spaced = F)
dat
```
```{r aggregate crime number, message=FALSE, warning=FALSE, paged.print=TRUE}
res <- dat %>%
  group_by(year, boro_nm) %>%
  filter(boro_nm != "") %>%
  dplyr::summarise(crimes = n()) 
res
```
```{r change to lowercase, message=FALSE, warning=FALSE, paged.print=TRUE}
#by_crime <- res %>% mutate_if(is.character, str_to_lower) 


by_crime <- arrests_df %>% select(year, arrest_boro) %>% group_by(year, arrest_boro) %>% dplyr::summarise(crimes = n())
colnames(by_crime) <- c("year", "boro_nm", "crimes" )
by_crime

```
```{r filter by unemployed, message=FALSE, warning=FALSE, paged.print=TRUE}
dat2 <- income_table
dat2$unemployed <- as.numeric(gsub(",", "", dat2$unemployed))
names(dat2)[1] <- "boro_nm"
subet <- dat2[c(1:2,5)]
by_unemployment <- subet %>%
  group_by(year, boro_nm) %>%
  dplyr::summarise(unemployed = round(mean(unemployed), 2)) #%>%
  #mutate_if(is.character, str_to_lower)
by_unemployment$boro_nm <- revalue(by_unemployment$boro_nm, c("Queens "="Queens"))
by_unemployment
```
```{r merge crime and unemployed, message=FALSE, warning=FALSE, paged.print=TRUE}
#joined <- Reduce(function(...) merge(..., all=T), list(by_crime, by_unemployment)) 
 

joined <- left_join(by_crime, by_unemployment, by = c("year"="year", "boro_nm"="boro_nm"))
joined



```

To start building the predictive model, we need to see if there is a correlation between our predictor and response. In this case, crimes and unemployed. We will begin by doing some exploratory data visualization. The function `ggpairs()`  from the `GGally package` was used to create a plot matrix demonstrating how the variables relate to one another.  

```{r correlation between crime and unemployed, message=FALSE, warning=FALSE, echo=FALSE}
ggpairs(data=joined, columns = 3:4, title="Crimes employed data")
```

There is essential regard that correlation doesn't imply causation, so constructing a regression model is imperative to comprehend whether we can use this variable as a predictor. 

We started by scrutinizing the relationship between the outcome and covariant. In our case, it is the number of crimes committed and the unemployment rate. It seems that their relationship is linear.

```{r explore-unemployed as predictor, message=FALSE, warning=FALSE, echo=FALSE}
theme_set(theme_bw())  # pre-set the bw theme.
g <- ggplot(joined, aes(unemployed, crimes)) + 
  geom_jitter() +
  geom_smooth(method="lm") +
  labs(subtitle="Crimes per unemployed: crimes vs unemployed numbers", 
       y="Crimes", 
       x="Unemployed", 
       title="Scatterplot with overlapping points", 
       caption="Source: joined")
ggMarginal(g, type = "boxplot", fill="transparent")
```
```{r unemployed regression, message=FALSE, warning=FALSE}
m_unemployed <- lm(crimes ~ unemployed, data = joined)
summary(m_unemployed)
```

As pointed by the simple linear regression, unemployment has an **R-squared  ~0.75**. This makes it a better predictor of the number of crimes. 
However, to make sure that our predictor model is reliable, we need to see if the residuals are so close to the actual value. This would give us a quality indicator of how is our prediction is fitting. 

```{r message=FALSE, warning=FALSE, echo=FALSE}
plot(m_unemployed, which=2, col=c("red"))  # Q-Q Plot
```

For our model, **the Q-Q plot** shows pretty good alignment to the the line with a few points at the top slightly offset.

```{r message=FALSE, warning=FALSE, echo=FALSE}
plot(m_unemployed, which=3, col=c("blue")) # Scale-Location Plot
```

The residuals are not reasonably well spread above and below a pretty non horizontal line. This may raise a concern for us, this means that the relationship between the two variables are not linear. So we tried to get investigate more mon building a mutlivariable regression model taking other variables into account.


```{r aggregate by category, message=FALSE, warning=FALSE}
by_cat <- arrests_df %>% select(year, arrest_boro, age_group, perp_sex, perp_race) %>% group_by(year, arrest_boro, age_group, perp_sex, perp_race) %>% dplyr::summarise(crimes=n())
colnames(by_cat) <- c("year", "boro_nm", "susp_age_group", "susp_sex", "susp_race", "crimes")
by_cat
```

Categorize age-group preparing for dummy variables

```{r construct dummy variables, message=FALSE, warning=FALSE}
dummy_df <- by_cat
dummy_df$susp_age_group <- revalue(by_cat$susp_age_group, c("<18"="child", "18-24"="youth", "25-44"="adult", "45-64"="senior", "65+" = "senior")) 
dummy_df
```

Converting the independent variables into factors

```{r convert variables into factors, message=FALSE, warning=FALSE}
#function to categorize and indicate the cofounder variable
#
# function to categorise - dummy variables
filtered <- dummy_df %>%
  filter(susp_age_group %in% c("child", "youth", "adult", "senior")) 
## change to factor level
filtered$boro_nm <- as.factor(filtered$boro_nm)
filtered$susp_age_group <- as.factor(filtered$susp_age_group)
filtered$susp_sex <- as.factor(filtered$susp_sex)
filtered$susp_race <- as.factor(filtered$susp_race)
# contrasts(filtered$susp_race)
# reference variable is AMERICAN INDIAN/ALASKAN NATIVE, we can rereference by using relevel(var, ref = "new_ref")
```

We will start with some exploratory analysis on the filtered dataset.

Having some information shown on plots would give a good idea as to which categorical variables are good predictive features and can be used to build a machine learning model.
Best plots for factor to factor variable comparison would be any of a jitter plot or heat map. I would use a jitter plot in this case for all of our factor-factor plots.

```{r exploratory analysis, warning=FALSE, message=FALSE, echo=FALSE, fig.height=6}
ggplot(data = filtered, mapping = aes(x = susp_race, y = crimes)) + 
  geom_jitter(aes(colour = susp_race)) +
  theme(axis.text.x = element_text(angle=90, vjust=0.6))
ggplot(data = filtered, mapping = aes(x = susp_sex, y = crimes)) + 
  geom_jitter(aes(colour = susp_sex)) 
ggplot(data = filtered, mapping = aes(x = susp_age_group, y = crimes)) + 
  geom_jitter(aes(colour = susp_age_group)) 
ggplot(data = filtered, mapping = aes(x = boro_nm, y = crimes)) + 
  geom_jitter(aes(colour = boro_nm)) + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```


```{r change reference to M, message=FALSE, warning=FALSE}
m_race <- lm(crimes ~ susp_race, data = filtered)
summary(m_race) # no significance
```


Taking other variables (susp_age_group, susp_sex, and boro_nm) into account.

```{r regression summary, warning=FALSE, message=FALSE}
m_all <- lm(crimes ~ susp_age_group + susp_sex + susp_race + boro_nm, data = filtered)
summary(m_all)
```

It can be seen that race **Black** is significantly associated with an average increase of 3219 in crime rates compared to other races. Now we will study the residuals.

```{r qqplot, message=FALSE, warning=FALSE, echo=FALSE}
plot(m_all, which=2, col=c("red"))  # Q-Q Plot
```

```{r scale location plot, message=FALSE, warning=FALSE, echo=FALSE}
plot(m_unemployed, which=3, col=c("blue")) # Scale-Location Plot
```

Same as when we used unemployed variables, we have concerns about residuals distribution resulted from the **Q-Q plot**. 

# Conclusion

Given that that for our model we had an Adjusted R-squared: 0.4175, this would indicate that the model does explain 41.75% of the variability.  
To see if this amount is significant, we analyze the variances. Since the p-values of the variances are near zero,  
**we have sufficient evidence to reject the null hypothesis, in that we can say that unemployment does impact crime**

```{r}
anova(m_all)
```


## What did we learn? 
1. While crime overall is decreasing in NYC, black individuals are still disportionaly inclined to commit more crimes. The largest coefficent in the regression model is where the suspect race is black, 3219.82. 

2. The Bronx remains the boro with the highest unemployment rate, but Brooklyn and Manhatten have the highest crime rates of the 5 boros. 

3. At a marco level, each increase in unemployment by one, results in a crime increase of 1.2209. At a more micro level, being a black or white/hispanic male is a good predictor of a crime. 
    
4. Build a geographic geomap for the commited crimes per borough


## Why is this important
1. Important in evaluating successes of policies over time
2. Important in shaping future police inforcement policy
3. Connection between unemployment and saftey



## Challenges

1. Working with very large data sets and how we filtered it down
2. Sourcing external scripts into Rmarkdown
3. Merging datasets with no distinct identifiers across each obsrvations  
4. Merging dataset with different observation values - lower & upper case
5. Determining which set of variables are a better fit for regression model



## Future Work

## References 

+ [GitHub Repo](https://github.com/dhairavc/DATA607-FinalProject)